{
  "id": 91,
  "title": "RAG for Tool Selection",
  "slug": "rag-for-tool-selection",
  "url": "https://knowledge.oculair.ca/books/unknown/page/rag-for-tool-selection",
  "updated_at": "2025-04-12T22:25:43.000000Z",
  "body_html": "<h1 id=\"bkmrk-embedding-based-tool\">Embedding-Based Tool Selection with RAG</h1>\n<p id=\"bkmrk-this-document-outlin\">This document outlines the embedding-based approach for implementing dynamic tool loading in Letta agents, using vector embeddings and semantic search (RAG) to efficiently select tools from a large collection.</p>\n<h2 id=\"bkmrk-overview\">Overview</h2>\n<p id=\"bkmrk-this-approach-levera\">This approach leverages vector embeddings to represent tools semantically, enabling efficient retrieval based on the user's query intent. By using a vector database and similarity search, this method scales well to hundreds or thousands of tools.</p>\n<h2 id=\"bkmrk-implementation-flow\">Implementation Flow</h2>\n<ol id=\"bkmrk-preprocess-tool-desc\">\n<li>Preprocess tool descriptions to generate vector embeddings</li>\n<li>Store embeddings in a vector database</li>\n<li>Convert user query to a vector embedding</li>\n<li>Retrieve semantically similar tools using vector similarity search</li>\n<li>Attach selected tools to Letta agent</li>\n<li>Maintain previously used tools for context continuity</li>\n</ol>\n<h2 id=\"bkmrk-code-implementation\">Code Implementation</h2>\n<pre id=\"bkmrk-def-setup_tool_embed\"><code class=\"language-python\">def setup_tool_embeddings(all_tools, embedding_model=\"text-embedding-ada-002\"):\n    \"\"\"Preprocess all tools to generate and store embeddings\"\"\"\n    \n    # Create a description for each tool that captures its functionality\n    tool_texts = []\n    for tool in all_tools:\n        # Combine relevant tool information\n        tool_text = f\"Tool Name: {tool.name}\\nDescription: {tool.description}\\nUsage Examples: {tool.examples}\"\n        tool_texts.append(tool_text)\n    \n    # Generate embeddings\n    embeddings = embedding_model.embed_documents(tool_texts)\n    \n    # Store in vector database with tool IDs as metadata\n    vector_db = VectorStore()\n    for i, embedding in enumerate(embeddings):\n        vector_db.add(\n            embedding=embedding,\n            metadata={\"tool_id\": all_tools[i].id}\n        )\n    \n    return vector_db\n\ndef select_tools_with_embeddings(query, vector_db, all_tools, previous_tools=None, top_k=10):\n    \"\"\"Select tools using embedding-based similarity search\"\"\"\n    \n    # Generate embedding for the query\n    query_embedding = embedding_model.embed_query(query)\n    \n    # Retrieve similar tools based on embedding similarity\n    similar_tool_results = vector_db.similarity_search(\n        query_embedding,\n        top_k=top_k\n    )\n    \n    # Extract tool IDs from search results\n    tool_ids = [result.metadata[\"tool_id\"] for result in similar_tool_results]\n    \n    # Get the actual tool objects\n    selected_tools = [tool for tool in all_tools if tool.id in tool_ids]\n    \n    # Include previously used tools for continuity\n    if previous_tools:\n        selected_tools = list(set(selected_tools + previous_tools))\n    \n    return selected_tools\n\ndef handle_query(query, vector_db, all_tools, previous_tools=None):\n    # Step 1: Select relevant tools using embeddings\n    relevant_tools = select_tools_with_embeddings(query, vector_db, all_tools, previous_tools)\n    \n    # Step 2: Attach tools to Letta agent\n    agent = attach_tools_to_agent(\"your-letta-agent-id\", relevant_tools)\n    \n    # Step 3: Let agent handle the query with available tools\n    response = prompt_agent(agent.id, query)\n    \n    return response, relevant_tools  # Return tools for next query\n</code></pre>\n<h2 id=\"bkmrk-recommended-embeddin\">Recommended Embedding Models</h2>\n<p id=\"bkmrk-several-embedding-mo\">Several embedding models work well for this approach:</p>\n<ol id=\"bkmrk-openai%27s-ada-embeddi\">\n<li><strong>OpenAI's Ada Embeddings</strong> - High quality with 1536 dimensions</li>\n<li><strong>Cohere Embed</strong> - Specifically designed for semantic retrieval</li>\n<li><strong>Sentence Transformers</strong> - Open source options like all-MiniLM-L6-v2</li>\n</ol>\n<h2 id=\"bkmrk-vector-databases\">Vector Databases</h2>\n<p id=\"bkmrk-compatible-vector-da\">Compatible vector databases include:</p>\n<ol id=\"bkmrk-pinecone---managed-v\">\n<li><strong>Pinecone</strong> - Managed vector DB with good scaling properties</li>\n<li><strong>Qdrant</strong> - Self-hostable with rich filtering capabilities</li>\n<li><strong>Chroma</strong> - Simple in-memory option for smaller tool sets</li>\n<li><strong>Weaviate</strong> - GraphQL-based semantic search engine</li>\n</ol>\n<h2 id=\"bkmrk-advantages\">Advantages</h2>\n<ul id=\"bkmrk-scalability%3A-efficie\">\n<li><strong>Scalability</strong>: Efficiently handles thousands of tools</li>\n<li><strong>Performance</strong>: Vector search is typically faster than model inference</li>\n<li><strong>Semantic Understanding</strong>: Captures meaning rather than just keywords</li>\n<li><strong>Flexibility</strong>: Can adjust similarity thresholds based on requirements</li>\n</ul>\n<h2 id=\"bkmrk-limitations\">Limitations</h2>\n<ul id=\"bkmrk-setup-complexity%3A-re\">\n<li><strong>Setup Complexity</strong>: Requires initial embedding generation and database setup</li>\n<li><strong>Maintenance Overhead</strong>: Tool embeddings must be updated when tools change</li>\n<li><strong>Cold Start</strong>: New tools need to be embedded before they can be discovered</li>\n<li><strong>Limited Reasoning</strong>: Pure vector search doesn't apply complex reasoning to tool selection</li>\n</ul>\n<h2 id=\"bkmrk-implementation-consi\">Implementation Considerations</h2>\n<ol id=\"bkmrk-embedding-strategy%3A-\">\n<li><strong>Embedding Strategy</strong>: Consider embedding tool name, description, and usage examples separately for better matching</li>\n<li><strong>Hybrid Search</strong>: Combine keyword and semantic search for more robust results</li>\n<li><strong>Metadata Filtering</strong>: Use metadata to filter tools by category before semantic search</li>\n<li><strong>Relevance Threshold</strong>: Set a minimum similarity score to avoid irrelevant tools</li>\n<li><strong>Periodic Updates</strong>: Re-embed tools periodically if descriptions are updated</li>\n</ol>\n<p id=\"bkmrk-this-approach-is-par\">This approach is particularly valuable when dealing with very large tool collections where traditional prompting approaches would become unwieldy.</p>\n",
  "tags": [],
  "book": "Dynamic Tool Loading for Letta",
  "chapter": ""
}